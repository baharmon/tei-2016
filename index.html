<section>
<h3 style="color: #888"><b>ACM</b> Tangible Embedded Embodied Interaction 2016</h3>
<h1 style="margin-top: 0.5em">Embodied Cognition with Tangible Landscape</h1>
<h4>Brendan Harmon, Anna Petrasova, Vaclav Petras, Helena Mitasova, &amp; Ross Meentemeyer</h4>
<img height="100px" style="margin-top: 2em" src="img/cgaBlack.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible user interface powered by open source GIS</h3>
<img height="150px" src="img/logo_black.png">
</section>

<!-- History -->
<section>
<h2>History</h2>
<img height="250px" src="img/illuminating_clay.png">
<img height="250px" src="img/tangeoms_2.jpg">
<p>An evolution of <b>Illuminating Clay</b> and the <b>Tangible Geospatial Modeling System</b></p>
<p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
<p style="font-size:0.75em"><a href="http://baharmon.github.io/publications/tangible_geospatial_modeling.pdf">L. Tateosian, H. Mitasova, B. A. Harmon, B. Fogleman, K. Weaver, and R. S. Harmon, “TanGeoMS: tangible geospatial modeling system.,” IEEE Trans. Vis. Comput. Graph., vol. 16, no. 6, pp. 1605–12, 2010.</a></p>
<p style="font-size:0.75em">Image source: <a href="http://tangible.media.mit.edu/project/illuminating-clay/">MIT Media Lab</a></p>
</section>

<!-- Concept -->
<section>
<h2>Concept</h2>
<img width="30%" src="img/tl_fill_dir_s_6.png">
<img width="30%" src="img/tl_fill_dir_s_6_interaction.png">
<img width="30%" src="img/tl_fill_dir_s_7.png">
<p>Coupling a digital and physical model of a landscape so that you can intuitively feel and shape it with your hands</p>
</section>

<!-- Real time -->
<section>
<h2>Near real-time interaction</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/tl_dam.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</section>

<!-- How it works -->
<section>
<h2>How-it-works</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through a continuous cycle of 3D scanning, geospatial modeling, and projection</p>
</section>

<!-- Science with Tangible Landscape -->
<section>
<h2>Intuitive scientific modeling with Tangible Landscape</h2>
<img width="25%" src="img/subsurface_1.jpg">
<img width="25%" src="img/subsurface_2.jpg">
<img width="40.55%" src="img/subsurface_3.jpg">
<p>Tangible Landscape is designed to make scientific data, models, and simulations exploratory, engaging, and fun</p>
</section>

<!-- Serious gaming with Tangible Landscape: Termites -->
<section>
<h2>Scientific gaming</h2>
<img width="30%" src="img/termite_game_1.jpg">
<img width="30%" src="img/termite_game_2.jpg">
<img width="30%" src="img/termite_game_3.jpg">
<h4 style="margin-top: 1em">Termite infestation game</h4>
<p>Structured problem solving with rules, challenging objectives, and scoring</p>
</section>

<!-- Serious gaming with Tangible Landscape: Coastal -->
<section>
<h2>Scientific gaming</h2>
<img width="22%" src="img/tl_coastal_1s.png">
<img width="22%" src="img/tl_coastal_2s.png">
<img width="22%" src="img/tl_coastal_3s.png">
<img width="22%" src="img/tl_coastal_4s.png">
<h4 style="margin-top: 1em">Coastal flooding game</h4>
</section>

<!-- Experiment: theory -->
<section>
<h2>Embodied cognition</h2>
<img width="30%" src="img/tl_difference_s_1.png">
<img width="30%" src="img/tl_difference_s_2.png">
<img width="30%" src="img/tl_difference_s_3.png">
<p>Theoretically tangible interaction should offload cognitive processes through bodily action, physical simulation, and digital computation</p>
</section>

<!-- Experiment: methods: spatial performance -->
<section>
<h2>Experiment</h2>
<img width="22.25%" src="img/anderson_7.jpg">
<img width="34%" src="img/magallanes_1.jpg">
<img width="34%" src="img/art_2.jpg">
<p>A comparative study of 3D spatial performance with hand modeling, digital modeling, and tangible interaction</p>
</section>

<!-- Experiment: results -->
<section>
<h2>Experiment</h2>
<img width="30%" src="img/diff_stddev_7.png">
<img width="30%" src="img/diff_stddev_1.png">
<img width="30%" src="img/diff_stddev_2.png">
<p><i>Spatial statistics:</i> the standard deviation of the differences of all participants using each technology</p>
</section>

<!-- Experiment: open science -->
<section>
<h2>Open Science</h2>
<img width="10%" src="img/Octocat.png">
<p>Fork us on GitHub</p>
<p style="font-size:0.75em"><a href="https://github.com/baharmon/tangible_topography">Repository with experiment instructions, scripts, data, and results</a></p>
<p style="font-size:0.75em"><a href="https://github.com/ncsu-osgeorel/grass-tangible-landscape">Repository for the Tangible Landscape plugin for GRASS GIS</a></p>
</section>

<!-- Future work: cognitive science -->
<section>
<h2>Future work</h2>
<img width="90%" src="img/future_system.png">
<!--
<img width="50%" src="img/future_system_schema.png">
<img width="40%" src="img/future_system.png">
-->
<p>Experiments using eye trackers, EEGs, and biometric sensors to study learning and creativity with Tangible Landscape</p>
</section>

<!-- Future work: digital fabrication -->
<section>
<h2>Future work</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/cnc_sand.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>In situ digital fabrication</p>
</section>

<!-- Discussion -->
